{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet DataScience - Entreprise TouNum\n",
    "\n",
    "## Méthodologie CRISP :\n",
    "\n",
    "|Auteurs|Centre|Modification|Date|\n",
    "|---|---|---|---|\n",
    "|Alexis Billequin - Clément Chabrier - Etienne Duverney - Adrien Kegler - Nicolas Mazard - Baptiste Saclier - Adrien Thevenet|Lyon|première version|14/01/2020|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding :\n",
    "\n",
    "#### Demande métier :\n",
    "\n",
    "Nous travaillons pour TouNum, une entreprise de numérisation des cassettes vidéos.Le but de ce projet est d'améliorer les images de cassette vidéo VHS pour qu'elles soient analysables.\n",
    "\n",
    "TouNum nous demande donc d'en un premier temps de travailler sur la restauration d'images [`PAL (Phase Alternating Line)`](https://www.wikiwand.com/fr/Phase_Alternating_Line) issu de cassettes VHS grâce au machine learning; Il faudra:\n",
    "- Détecter/réduire/faire disparaitre les défauts\n",
    "- Rendre le processus automatique\n",
    "- Pouvoir s'adapter à tous les types de données d'images\n",
    "- Rendre la solution lisible sous la forme de notebooks [`Jupyter`](https://jupyter.org/)\n",
    "- Exporter le modèle de machine learning via [`Pickle`](https://docs.python.org/fr/3.7/library/pickle.html)\n",
    "- En bonus:\n",
    "    - Présenter des pistes de réflexions sur l'amélioration du modèle pour le traitement de vidéos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation du résultat :\n",
    "\n",
    "Pour évaluer l'efficacité de notre solution, nous nous baserons sur une [`évaluation de la qualité d'image (EQI)`](https://www.researchgate.net/publication/322643565_Etude_comparative_des_methodes_d'evaluation_de_la_qualite_d'image). Il en existe trois catégorie:\n",
    "- Les méthodes avec Référence: l'algorithme a un accès a une version parfaite de l'image avec laquelle il peut comparer la version déformée.\n",
    "- Les méthodes sans Référence: l'algorithme n'a accès qu'à l'image déformée et doit estimer la qualité de l'image sans la connaissance de la version parfaite.\n",
    "- Les méthodes avec Référence partielle: l'image de référence est disponible partiellement, elle est connu sous le nom d'estimation de la qualité de référence réduite\n",
    "\n",
    "Il existe plusieur métrique d'EQI:\n",
    "- L'erreur moyenne quadratique ou Mean Square Error (MSE) : comparer une image revalorisé avec l'image non dégrader, en se basant sur la MSE entre les pixels des deux images.\n",
    "    $$MSE = \\frac{1}{M*N} \\sum_{m-1}^{M} \\sum_{n-1}^{N}(I(m,n) - J(m,n)) $$ \n",
    "  $(M * N)$ est la taille de l'image, $I(m,n)$ et $J(m,n)$ sont les amplitudes des images parfaites et revalorisé  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le rapport crête signal sur bruit ou Peak Signal Noise Ratio (PSNR): au lieu de mesurer les distorsion, cette valeur mesure la fidélité, c'est à dire qu'elle est proportionnelle à la qualité.\n",
    "    $$ PSNR = 10 \\log_{10}(\\frac{{l_{max}}^2}{MSE}) $$\n",
    "    $l_{max}$ désigne la luminance maximale possible pour une image en niveau de gris. Si cette valeur est infinie cela veut dire que l'image est non dégardée, et plus la valeur est dégradée plus cette valeur décroît.  \n",
    "Dans le cas des images couleur, aucune définition précisede l’adaptation de l’équation du PSNR n’existe. Plusieursvariantes existent :\n",
    "   - Le PSNR est calculé sur chacun des trois plans colorimétriques puis une moyenne est ensuite effectuée afin d'obtenir une valeur finie\n",
    "   - La distance euclidienne entre deux pixels de couleur est utilisée dans l'équation originale\n",
    "cette mesure ne permet pas de prendre en compte la sensibilité du système visuelhumain, et n’apparaît pas être performante.\n",
    "\n",
    "- Le rapport signal sur bruit ou Signal Noise Ratio (SNR): Variante du PSNR liant le MSE à l'énergie moyenne de l'image.\n",
    "    $$ SNR = 10 \\log_{10}(\\frac{\\frac{1}{N}\\sum l^2}{MSE}) $$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'index de Similarité Structurelle (SSIM): est une mesure de similarité entre deux images numériques plustôt que la différence pixel à pixel.  \n",
    "    La  métrique  SSIM  est  calculée  sur  plusieurs  fenêtres d'une image de taille NxN. On dénote x et y  les vecteurs de l’image originale et déformée respectivement. \n",
    "    \n",
    "    $$SSIM(x, y) = \\frac{(2\\mu_x\\mu_y+c_1)(\\sigma_{xy} + c_2)}{(\\mu_{x}^{2} + \\mu_{y}^{2} + c_1)(\\sigma_{x}^{2} + \\sigma_{y}^{2} + c_2)}$$  \n",
    "    \n",
    "    La méthode SSIM est clairement plus impliquée que la méthode MSE, mais l'essentiel est que la méthode SSIM tente de modéliser le changement perçu dans les informations structurelles de l'image.   \n",
    "    Les paramètres de l'équation comprennent l'emplacement (x, y) de la fenêtre N x N dans chaque image, la moyenne des intensités($\\sigma$) des pixels dans les directions x et y, la variance des intensités ($\\mu$) dans les directions x et y, ainsi que la covariance ($c_1$ et $c_2$) qui sont des constantes. La valeur de SSIM peut varier entre -1 et 1, où 1 indique une similarité parfaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_mse as mse\n",
    "from skimage.measure import compare_nrmse as nrmse\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(imageA, imageB, title):\n",
    "    # compute the mean squared error and structural similarity\n",
    "    # index for the images\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB, multichannel =True)\n",
    "    n = nrmse(imageA, imageB)\n",
    "    p = psnr(imageA, imageB)\n",
    "\n",
    "    # setup the figure\n",
    "    fig = plt.figure(title)\n",
    "    plt.suptitle(\"MSE: %.2f, SSIM: %.2f, NRMSE: %.2f, PSNR: %.2f\" % (m, s, n, p))\n",
    "\n",
    "    # show first image\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(imageA)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # show the second image\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(imageB)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # show the images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding :\n",
    "\n",
    "A l'aide du dataSet fourni nous avons pu identifié 10 défauts sur les images:\n",
    "\n",
    "* **Pinking** : Barre filtrante Magenta\n",
    "* **Greening** : Barre filtrante Verte\n",
    "* **Tearing** : Distortion, ligne déformante (I devient <)\n",
    "* **Noise** : Bruis analogique (4 catégories types: gaussian - localvar - speckle - poisson)\n",
    "* **Black Line** : Ligne noir fine horizontal\n",
    "* **White Line** : Ligne blanche fine horizontal\n",
    "* **Over-exposure** : Surexposition en luminausité\n",
    "* **Blur**: traits des objets moins distincts\n",
    "* **Color shifting** : Aberration chromatiques Rouges et Vertes\n",
    "* **JPEG Artefact** : Artefactes de compression JPEG\n",
    "* **Posterisation** : Réduction du nombre valeurs des dégradés\n",
    "\n",
    "|Pinking|Greening|Tearing|Noise|Black Line|Posterisation|\n",
    "|:-----:|:------:|:-----:|:---:|:--------:|:-----------:|\n",
    "|![Pinking](../examples/pinking.png)|![Greening](../examples/greening.png)|![Tearing](../examples/tearing.png)|![Noise](../examples/noise.png)|![Black Line](../examples/black-line.png)|![Posterisation](../examples/posterisation.png)|\n",
    "|**White Line**|**Over-exposure**|**Blur**|**Color Shifting**|**JPEG Artefact**|\n",
    "|![White Line](../examples/white-line.png)|![Over-exposure](../examples/over-exposure.png)|![Blur](../examples/blur.png)|![Color Shifting](../examples/color-shifting.png)|![JPEG Artefact](../examples/jpeg-artefact.png)|\n",
    "\n",
    "En observant la redondance des défauts nous avons défini une echelle de gravité de ces derniers sur les images:\n",
    "1. Over-exposure  <!--add impact avec critère evaluation -->\n",
    "2. Noise\n",
    "3. Blur\n",
    "4. Posterization\n",
    "5. Greening/Pinking\n",
    "6. Tearing\n",
    "7. Color Shift\n",
    "8. Black/White Line\n",
    "9. JPEG Artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
